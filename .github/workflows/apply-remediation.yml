name: Apply Remediation

on:
  pull_request:
    types: [opened, synchronize, closed]
    paths:
      - 'remediation/*.tf'

permissions:
  contents: read
  id-token: write
  actions: write
  pull-requests: write

jobs:
  # -------------------------------------------------------
  # Plan: PR Ïó¥Î¶¥ Îïå Ïã§Ìñâ ‚Üí plan Í≤∞Í≥ºÎ•º PR. ÏΩîÎ©òÌä∏Î°ú Í≤åÏãú
  # -------------------------------------------------------
  plan:
    if: github.event.pull_request.merged != true && github.event.action != 'closed'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ap-northeast-2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: Install IaC quality tools (tflint + tfsec)
        run: |
          curl -sSL -o /usr/local/bin/tfsec https://github.com/aquasecurity/tfsec/releases/latest/download/tfsec-linux-amd64
          chmod +x /usr/local/bin/tfsec
          curl -sSL -o /tmp/tflint.zip https://github.com/terraform-linters/tflint/releases/latest/download/tflint_linux_amd64.zip
          unzip -q /tmp/tflint.zip -d /tmp
          mv /tmp/tflint /usr/local/bin/tflint
          tflint --init

      - name: Collect changed remediation files
        id: changed
        run: |
          files=$(git diff --name-status ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }} -- 'remediation/*.tf' | awk '$1!="D"{print $NF}' | tr '\n' ' ')
          echo "files=$files" >> $GITHUB_OUTPUT

      - name: Terraform Plan (per file)
        id: plan
        continue-on-error: true
        run: |
          set -euo pipefail
          : > /tmp/tfplan.txt
          : > /tmp/tfgate.txt
          exitcode=0

          if [ -z "${{ steps.changed.outputs.files }}" ]; then
            echo "No remediation files changed." >> /tmp/tfplan.txt
          else
            for file in ${{ steps.changed.outputs.files }}; do
              echo "### $file" >> /tmp/tfplan.txt
              echo "### $file" >> /tmp/tfgate.txt
              if [ ! -f "$file" ]; then
                echo "(skip missing file: $file)" >> /tmp/tfplan.txt
                echo "(skip missing file: $file)" >> /tmp/tfgate.txt
                continue
              fi
              work=$(mktemp -d)
              cp "$file" "$work/main.tf"

              python3 - "$work/main.tf" <<'PY'
          import re, sys, pathlib
          path = pathlib.Path(sys.argv[1])
          lines = path.read_text().splitlines()
          out = []
          in_provider = False
          in_import = False
          in_heredoc = False
          heredoc_marker = None
          brace = 0
          import_brace = 0
          comment_tail = False
          # S3 deprecated ÏÜçÏÑ± Ï†úÍ±∞Ïö©
          in_s3_bucket = False
          s3_brace = 0
          in_dep_block = False
          dep_brace = 0
          # Ï§ëÎ≥µ data Î∏îÎ°ù Ï†úÍ±∞Ïö©
          FRAMEWORK_DATA = {
              ('aws_caller_identity', 'current'),
              ('aws_region', 'current'),
              ('aws_partition', 'current'),
          }
          skip_data = False
          data_brace = 0

          for line in lines:
              # heredoc ÎÇ¥Î∂Ä: ÎÇ¥Ïö© Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ
              if in_heredoc:
                  out.append(line)
                  if line.strip() == heredoc_marker:
                      in_heredoc = False
                      heredoc_marker = None
                  continue
              # heredoc ÏãúÏûë Í∞êÏßÄ
              hm = re.search(r'<<-?\s*([A-Za-z0-9_]+)\s*$', line)
              if hm and not in_provider:
                  in_heredoc = True
                  heredoc_marker = hm.group(1)
                  out.append(line)
                  continue
              # Ï§ëÎ≥µ data Î∏îÎ°ù Ïä§ÌÇµ
              if skip_data:
                  data_brace += line.count('{') - line.count('}')
                  if data_brace <= 0:
                      skip_data = False
                  continue
              dm = re.match(r'^\s*data\s+"([^"]+)"\s+"([^"]+)"\s*\{', line)
              if dm and (dm.group(1), dm.group(2)) in FRAMEWORK_DATA:
                  skip_data = True
                  data_brace = line.count('{') - line.count('}')
                  if data_brace <= 0:
                      skip_data = False
                  continue
              # HCL ÏãúÏûë Ìå®ÌÑ¥ (comment_tail Î¶¨ÏÖãÏö©)
              HCL_START = re.compile(r'^\s*(#|//|resource\b|data\b|provider\b|variable\b|locals\b|terraform\b|output\b|module\b|\})')
              if not comment_tail and re.match(r'^\s*(This|The)\s+.*Terraform code', line):
                  comment_tail = True
              if comment_tail:
                  if HCL_START.match(line):
                      comment_tail = False
                  else:
                      out.append('# ' + line)
                      continue
              if re.match(r'^\s*\d+\.\s', line):
                  out.append('# ' + line)
                  continue
              if not in_provider and re.match(r'^\s*provider\s+"aws"\s*\{', line):
                  in_provider = True
                  brace += line.count('{') - line.count('}')
                  if brace <= 0:
                      in_provider = False
                  continue
              if in_provider:
                  brace += line.count('{') - line.count('}')
                  if brace <= 0:
                      in_provider = False
                  continue
              # Track import blocks (do not strip id= inside them)
              if not in_import and re.match(r'^\s*import\s*\{', line):
                  in_import = True
                  import_brace = line.count('{') - line.count('}')
                  out.append(line)
                  if import_brace <= 0:
                      in_import = False
                  continue
              if in_import:
                  import_brace += line.count('{') - line.count('}')
                  out.append(line)
                  if import_brace <= 0:
                      in_import = False
                  continue
              # Strip provider alias references inside resource/data blocks
              if re.match(r'^\s*provider\s*=\s*aws\.\S+', line):
                  continue
              # Strip computed/read-only attributes that AI incorrectly sets
              if re.match(r'^\s*(arn|id|owner_id|unique_id|creation_date)\s*=', line):
                  continue
              # S3 bucket deprecated ÏÜçÏÑ± Ï†úÍ±∞
              if not in_s3_bucket and re.match(r'^\s*resource\s+"aws_s3_bucket"\s+"[^"]+"\s*\{', line):
                  in_s3_bucket = True
                  s3_brace = line.count('{') - line.count('}')
                  out.append(line)
                  continue
              if in_s3_bucket:
                  if in_dep_block:
                      dep_brace += line.count('{') - line.count('}')
                      s3_brace += line.count('{') - line.count('}')
                      if dep_brace <= 0:
                          in_dep_block = False
                      if s3_brace <= 0:
                          in_s3_bucket = False
                      continue
                  if re.match(r'^\s*acl\s*=', line):
                      s3_brace += line.count('{') - line.count('}')
                      if s3_brace <= 0:
                          in_s3_bucket = False
                      continue
                  if re.match(r'^\s*server_side_encryption_configuration\s*\{', line):
                      in_dep_block = True
                      dep_brace = line.count('{') - line.count('}')
                      s3_brace += line.count('{') - line.count('}')
                      if dep_brace <= 0:
                          in_dep_block = False
                      if s3_brace <= 0:
                          in_s3_bucket = False
                      continue
                  s3_brace += line.count('{') - line.count('}')
                  out.append(line)
                  if s3_brace <= 0:
                      in_s3_bucket = False
                  continue
              out.append(line)

          path.write_text("\n".join(out) + "\n")
          PY

              cat > "$work/backend.tf" <<'EOF'
          terraform {
            backend "local" {
              path = "terraform.tfstate"
            }
          }
          EOF

              cat > "$work/provider.tf" <<'EOF'
          provider "aws" {
            region = "ap-northeast-2"
          }
          EOF

              # Í≥µÌÜµ data source (Ï§ëÎ≥µ Î∞©ÏßÄ)
              cat > "$work/data.tf" <<'EOF'
          data "aws_caller_identity" "current" {}
          data "aws_region" "current" {}
          data "aws_partition" "current" {}
          EOF

              terraform -chdir="$work" init -input=false 2>&1 | tee -a /tmp/tfplan.txt
              if ! (cd "$work" && tflint -f compact 2>&1 | tee -a /tmp/tfgate.txt); then
                echo "SKIP $file: tflint failed" | tee -a /tmp/tfplan.txt /tmp/tfgate.txt
                exitcode=1
                continue
              fi
              if ! tfsec --no-colour "$work" 2>&1 | tee -a /tmp/tfgate.txt; then
                echo "SKIP $file: tfsec failed" | tee -a /tmp/tfplan.txt /tmp/tfgate.txt
                exitcode=1
                continue
              fi
              if ! terraform -chdir="$work" validate 2>&1 | tee -a /tmp/tfplan.txt /tmp/tfgate.txt; then
                echo "SKIP $file: validate failed" | tee -a /tmp/tfplan.txt /tmp/tfgate.txt
                exitcode=1
                continue
              fi
              terraform -chdir="$work" plan -no-color | tee -a /tmp/tfplan.txt
              if [ ${PIPESTATUS[0]} -ne 0 ]; then exitcode=1; fi
            done
          fi

          echo "exitcode=$exitcode" >> "$GITHUB_OUTPUT"

      - name: Post Plan to PR comment
        uses: actions/github-script@v7
        env:
          PLAN_OUTPUT: ${{ steps.plan.outputs.exitcode }}
        with:
          script: |
            const fs = require('fs');
            let plan = fs.readFileSync('/tmp/tfplan.txt', 'utf8');

            // 65535Ïûê Ï†úÌïú ÎåÄÎπÑ truncate
            if (plan.length > 60000) {
              plan = plan.substring(0, 60000) + '\n\n... (truncated)';
            }

            const exitcode = process.env.PLAN_OUTPUT;
            const status = exitcode === '0' ? '‚úÖ Plan Succeeded' : '‚ùå Plan Failed';

            const body = `### Terraform Plan Result - ${status}

            <details>
            <summary>Plan ÏÉÅÏÑ∏ Î≥¥Í∏∞ (ÌÅ¥Î¶≠)</summary>

            \`\`\`
            ${plan}
            \`\`\`

            </details>

            > üí° Ïù¥ PRÏùÑ Î®∏ÏßÄÌïòÎ©¥ ÏúÑ Î¶¨ÏÜåÏä§Í∞Ä AWSÏóê ÏûêÎèô Ï†ÅÏö©Îê©ÎãàÎã§.
            > ‚ö†Ô∏è ÎπÑÏö© Î∞úÏÉù Î¶¨ÏÜåÏä§Í∞Ä ÏûàÎäîÏßÄ Î∞òÎìúÏãú ÌôïÏù∏ÌïòÏÑ∏Ïöî.`;

            // Í∏∞Ï°¥ bot ÏΩîÎ©òÌä∏ Ï∞æÏïÑÏÑú ÏóÖÎç∞Ïù¥Ìä∏ (Ï§ëÎ≥µ Î∞©ÏßÄ)
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('Terraform Plan Result')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body,
              });
            }

      - name: Fail if plan failed
        if: steps.plan.outputs.exitcode != '0'
        run: exit 1

      - name: Upload quality gate logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: remediation-quality-gates
          path: /tmp/tfgate.txt

  # -------------------------------------------------------
  # Apply: PR Î®∏ÏßÄ ÌõÑ Ïã§Ìñâ ‚Üí Ïã§Ï†ú AWS Ï†ÅÏö©
  # -------------------------------------------------------
  apply:
    if: github.event.pull_request.merged == true
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ap-northeast-2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: Install IaC quality tools (tflint + tfsec)
        run: |
          curl -sSL -o /usr/local/bin/tfsec https://github.com/aquasecurity/tfsec/releases/latest/download/tfsec-linux-amd64
          chmod +x /usr/local/bin/tfsec
          curl -sSL -o /tmp/tflint.zip https://github.com/terraform-linters/tflint/releases/latest/download/tflint_linux_amd64.zip
          unzip -q /tmp/tflint.zip -d /tmp
          mv /tmp/tflint /usr/local/bin/tflint
          tflint --init

      - name: Collect changed remediation files
        id: changed
        run: |
          files=$(git diff --name-status ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }} -- 'remediation/*.tf' | awk '$1!="D"{print $NF}' | tr '\n' ' ')
          echo "files=$files" >> $GITHUB_OUTPUT

      - name: Terraform Apply (per file)
        run: |
          set -euo pipefail
          : > /tmp/tfapply.txt
          if [ -z "${{ steps.changed.outputs.files }}" ]; then
            echo "No remediation files changed."
            exit 0
          fi

          for file in ${{ steps.changed.outputs.files }}; do
            echo "### $file" >> /tmp/tfapply.txt
            if [ ! -f "$file" ]; then
              echo "Skip missing file: $file"
              echo "Skip missing file: $file" >> /tmp/tfapply.txt
              continue
            fi
            work=$(mktemp -d)
            cp "$file" "$work/main.tf"

            python3 - "$work/main.tf" <<'PY'
          import re, sys, pathlib
          path = pathlib.Path(sys.argv[1])
          lines = path.read_text().splitlines()
          out = []
          in_provider = False
          in_import = False
          in_heredoc = False
          heredoc_marker = None
          brace = 0
          import_brace = 0
          comment_tail = False
          # S3 deprecated ÏÜçÏÑ± Ï†úÍ±∞Ïö©
          in_s3_bucket = False
          s3_brace = 0
          in_dep_block = False
          dep_brace = 0
          # Ï§ëÎ≥µ data Î∏îÎ°ù Ï†úÍ±∞Ïö©
          FRAMEWORK_DATA = {
              ('aws_caller_identity', 'current'),
              ('aws_region', 'current'),
              ('aws_partition', 'current'),
          }
          skip_data = False
          data_brace = 0

          for line in lines:
              # heredoc ÎÇ¥Î∂Ä: ÎÇ¥Ïö© Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ
              if in_heredoc:
                  out.append(line)
                  if line.strip() == heredoc_marker:
                      in_heredoc = False
                      heredoc_marker = None
                  continue
              # heredoc ÏãúÏûë Í∞êÏßÄ
              hm = re.search(r'<<-?\s*([A-Za-z0-9_]+)\s*$', line)
              if hm and not in_provider:
                  in_heredoc = True
                  heredoc_marker = hm.group(1)
                  out.append(line)
                  continue
              # Ï§ëÎ≥µ data Î∏îÎ°ù Ïä§ÌÇµ
              if skip_data:
                  data_brace += line.count('{') - line.count('}')
                  if data_brace <= 0:
                      skip_data = False
                  continue
              dm = re.match(r'^\s*data\s+"([^"]+)"\s+"([^"]+)"\s*\{', line)
              if dm and (dm.group(1), dm.group(2)) in FRAMEWORK_DATA:
                  skip_data = True
                  data_brace = line.count('{') - line.count('}')
                  if data_brace <= 0:
                      skip_data = False
                  continue
              # HCL ÏãúÏûë Ìå®ÌÑ¥ (comment_tail Î¶¨ÏÖãÏö©)
              HCL_START = re.compile(r'^\s*(#|//|resource\b|data\b|provider\b|variable\b|locals\b|terraform\b|output\b|module\b|\})')
              if not comment_tail and re.match(r'^\s*(This|The)\s+.*Terraform code', line):
                  comment_tail = True
              if comment_tail:
                  if HCL_START.match(line):
                      comment_tail = False
                  else:
                      out.append('# ' + line)
                      continue
              if re.match(r'^\s*\d+\.\s', line):
                  out.append('# ' + line)
                  continue
              if not in_provider and re.match(r'^\s*provider\s+"aws"\s*\{', line):
                  in_provider = True
                  brace += line.count('{') - line.count('}')
                  if brace <= 0:
                      in_provider = False
                  continue
              if in_provider:
                  brace += line.count('{') - line.count('}')
                  if brace <= 0:
                      in_provider = False
                  continue
              # Track import blocks (do not strip id= inside them)
              if not in_import and re.match(r'^\s*import\s*\{', line):
                  in_import = True
                  import_brace = line.count('{') - line.count('}')
                  out.append(line)
                  if import_brace <= 0:
                      in_import = False
                  continue
              if in_import:
                  import_brace += line.count('{') - line.count('}')
                  out.append(line)
                  if import_brace <= 0:
                      in_import = False
                  continue
              # Strip provider alias references inside resource/data blocks
              if re.match(r'^\s*provider\s*=\s*aws\.\S+', line):
                  continue
              # Strip computed/read-only attributes that AI incorrectly sets
              if re.match(r'^\s*(arn|id|owner_id|unique_id|creation_date)\s*=', line):
                  continue
              # S3 bucket deprecated ÏÜçÏÑ± Ï†úÍ±∞
              if not in_s3_bucket and re.match(r'^\s*resource\s+"aws_s3_bucket"\s+"[^"]+"\s*\{', line):
                  in_s3_bucket = True
                  s3_brace = line.count('{') - line.count('}')
                  out.append(line)
                  continue
              if in_s3_bucket:
                  if in_dep_block:
                      dep_brace += line.count('{') - line.count('}')
                      s3_brace += line.count('{') - line.count('}')
                      if dep_brace <= 0:
                          in_dep_block = False
                      if s3_brace <= 0:
                          in_s3_bucket = False
                      continue
                  if re.match(r'^\s*acl\s*=', line):
                      s3_brace += line.count('{') - line.count('}')
                      if s3_brace <= 0:
                          in_s3_bucket = False
                      continue
                  if re.match(r'^\s*server_side_encryption_configuration\s*\{', line):
                      in_dep_block = True
                      dep_brace = line.count('{') - line.count('}')
                      s3_brace += line.count('{') - line.count('}')
                      if dep_brace <= 0:
                          in_dep_block = False
                      if s3_brace <= 0:
                          in_s3_bucket = False
                      continue
                  s3_brace += line.count('{') - line.count('}')
                  out.append(line)
                  if s3_brace <= 0:
                      in_s3_bucket = False
                  continue
              out.append(line)

          path.write_text("\n".join(out) + "\n")
          PY

            cat > "$work/backend.tf" <<'EOF'
          terraform {
            backend "local" {
              path = "terraform.tfstate"
            }
          }
          EOF

            cat > "$work/provider.tf" <<'EOF'
          provider "aws" {
            region = "ap-northeast-2"
          }
          EOF

            # Í≥µÌÜµ data source (Ï§ëÎ≥µ Î∞©ÏßÄ)
            cat > "$work/data.tf" <<'EOF'
          data "aws_caller_identity" "current" {}
          data "aws_region" "current" {}
          data "aws_partition" "current" {}
          EOF

            terraform -chdir="$work" init -input=false 2>&1 | tee -a /tmp/tfapply.txt
            if ! (cd "$work" && tflint -f compact 2>&1 | tee -a /tmp/tfapply.txt); then
              echo "SKIP $file: tflint failed" | tee -a /tmp/tfapply.txt
              continue
            fi
            if ! tfsec --no-colour "$work" 2>&1 | tee -a /tmp/tfapply.txt; then
              echo "SKIP $file: tfsec failed" | tee -a /tmp/tfapply.txt
              continue
            fi
            if ! terraform -chdir="$work" validate 2>&1 | tee -a /tmp/tfapply.txt; then
              echo "SKIP $file: validate failed" | tee -a /tmp/tfapply.txt
              continue
            fi
            if ! terraform -chdir="$work" plan -out=tfplan 2>&1 | tee -a /tmp/tfapply.txt; then
              echo "SKIP $file: plan failed" | tee -a /tmp/tfapply.txt
              continue
            fi
            terraform -chdir="$work" apply -auto-approve tfplan 2>&1 | tee -a /tmp/tfapply.txt
          done

      - name: Trigger Prowler Re-scan
        run: |
          gh workflow run prowler-security-scan.yml
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload apply logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: remediation-apply-logs
          path: /tmp/tfapply.txt
