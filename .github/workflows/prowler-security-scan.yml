name: ProwlerSecurityScan

on:
  pull_request:
  push:
    branches: ["main"]

permissions:
  contents: write
  id-token: write
  pull-requests: write

jobs:
  prowler:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure folders
        run: |
          mkdir -p output reports scripts mcp/output

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ap-northeast-2

      - name: Install Prowler + deps
        run: |
          pip install prowler pandas openpyxl boto3

      - name: Run Prowler (CIS 1.4 / ap-northeast-2)
        continue-on-error: true
        run: |
          prowler aws \
            --region ap-northeast-2 \
            --compliance cis_1.4_aws \
            --severity medium \
            --output-directory output \
            --output-formats json-ocsf html csv

      - name: Normalize + Score + AI Assist + Runbook + OCSF
        run: |
          python mcp/pipeline/normalize.py --input "output/*.csv" --output mcp/output/findings-normalized.csv
          python mcp/pipeline/score.py --input mcp/output/findings-normalized.csv --output mcp/output/findings-scored.csv
          python mcp/pipeline/ai_assist.py --input mcp/output/findings-scored.csv --output mcp/output/findings-scored-ai.csv
          python mcp/pipeline/build_runbook.py --input mcp/output/findings-scored-ai.csv --template mcp/templates/runbook.md --output mcp/output/runbook.md
          python mcp/pipeline/export_ocsf.py --input "output/*.ocsf.json" --output mcp/output/ocsf-findings.json

      - name: Build Excel report (optional)
        if: always()
        run: |
          if [ -f scripts/json_to_excel.py ]; then
            python scripts/json_to_excel.py
          else
            echo "scripts/json_to_excel.py not found - skip"
          fi

      - name: Upload output (raw)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: prowler-output
          path: output/

      - name: Upload MCP artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mcp-output
          path: mcp/output/

      - name: Upload reports (human)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: prowler-reports
          path: reports/

      - name: Install PyYAML for IaC fallback
        if: github.ref == 'refs/heads/main'
        run: pip install pyyaml

      - name: Setup Terraform (for validate during generation)
        if: github.ref == 'refs/heads/main'
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: Generate Remediation Code
        if: github.ref == 'refs/heads/main'
        run: |
          mkdir -p remediation
          echo "=== Input CSV row count ==="
          wc -l mcp/output/findings-scored-ai.csv || true
          python mcp/pipeline/generate_remediation.py \
            --input mcp/output/findings-scored-ai.csv \
            --output-dir remediation/
          echo "=== Generated .tf files ==="
          ls -la remediation/*.tf 2>/dev/null || echo "No .tf files generated"
          echo "=== Manifest ==="
          cat remediation/manifest.json 2>/dev/null || echo "No manifest"

      - name: Upload Remediation artifacts
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: remediation
          path: remediation/
      - name: Create Remediation PRs (by category, overwrite branch)
        if: github.ref == 'refs/heads/main' && hashFiles('remediation/*.tf') != ''
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          python - <<'PY' > /tmp/remediation-groups.txt
          import glob
          import json
          import os
          import re
          from collections import defaultdict

          def categorize(check_id: str) -> str:
              cid = (check_id or "").lower()
              if cid.startswith("iam_"):
                  return "iam"
              if cid.startswith("s3_"):
                  return "s3"
              if cid.startswith("cloudtrail_"):
                  return "cloudtrail"
              if cid.startswith("cloudwatch_"):
                  return "cloudwatch"
              if cid.startswith("kms_"):
                  return "kms"
              if cid.startswith("ec2_") or cid.startswith("vpc_") or cid.startswith("network"):
                  return "network-ec2-vpc"
              if cid.startswith("organizations_") or cid.startswith("account_"):
                  return "org-account"
              return "other"

          groups = defaultdict(list)
          manifest = "remediation/manifest.json"
          if os.path.exists(manifest):
              try:
                  with open(manifest) as f:
                      data = json.load(f)
              except Exception:
                  data = []
              for item in data:
                  cat = item.get("category") or categorize(item.get("check_id", ""))
                  file = item.get("file")
                  if not file:
                      continue
                  groups[cat].append(os.path.join("remediation", file))
          else:
              for file in glob.glob("remediation/*.tf"):
                  base = os.path.basename(file)
                  check_id = re.sub(r"^fix-", "", base)
                  check_id = re.sub(r"\.tf$", "", check_id)
                  cat = categorize(check_id)
                  groups[cat].append(file)

          for cat, files in groups.items():
              safe = re.sub(r"[^a-z0-9-]+", "-", cat.lower()).strip("-") or "other"
              print(safe + "|" + "|".join(sorted(set(files))))
          PY

          if [ ! -s /tmp/remediation-groups.txt ]; then
            echo "No remediation groups found; skipping PR creation."
            exit 0
          fi

          while IFS= read -r line; do
            cat="${line%%|*}"
            rest="${line#*|}"
            IFS='|' read -r -a files <<< "$rest"
            if [ -z "$cat" ] || [ "${#files[@]}" -eq 0 ]; then
              continue
            fi

            BRANCH="remediation/${cat}"

            # open PR exists?
            EXISTING_PR=$(gh pr list --head "$BRANCH" --base main --state open --json number --jq '.[0].number' 2>/dev/null || echo "")

            # reset branch to main, then commit only the category files
            git checkout -B "$BRANCH" main
            git add -- "${files[@]}"
            git commit -m "fix: remediation (${cat})" || { git checkout main; continue; }
            git push origin "$BRANCH" --force

            if [ -z "$EXISTING_PR" ]; then
              printf "%s\n" \
                "## Auto-generated Terraform Remediation (${cat})" \
                "" \
                "This PR contains automatically generated Terraform fixes for category **${cat}**." \
                "" \
                "### Review Checklist" \
                "- [ ] Verify Terraform code is correct" \
                "- [ ] Check for unintended changes" \
                "- [ ] Confirm resources match the finding" \
                "" \
                "**Merge this PR to automatically apply fixes to AWS.**" \
                "" \
                "---" \
                "Generated by Prowler + Claude AI pipeline." \
                > /tmp/pr-body.md

              gh pr create \
                --title "Security Remediation (${cat})" \
                --body-file /tmp/pr-body.md \
                --base main \
                --head "$BRANCH"
            else
              echo "PR #${EXISTING_PR} already exists for ${BRANCH} – updated via force-push."
            fi
          done < /tmp/remediation-groups.txt


