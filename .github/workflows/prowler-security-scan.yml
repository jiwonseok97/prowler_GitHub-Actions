name: ProwlerSecurityScan

on:
  # PR?ì„œ??ë³´ì•ˆ ?ê?/ ë¦¬í¬???ì„±
  pull_request:
  # main ë¸Œëžœì¹˜ì— ë¨¸ì??˜ë©´ remediation + PR ?ë™ ?ì„±ê¹Œì? ?˜í–‰
  push:
    branches: ["main"]
  # ?˜ë™ ?¬ì‹¤??Apply ?´í›„ ?¬ìŠ¤ìº??¸ë¦¬ê±°ìš©)
  workflow_dispatch:

# ê¸°ë³¸?€ ìµœì†Œ ê¶Œí•œ (?½ê¸° ?„ìš©)
permissions:
  contents: read

env:
  BEDROCK_MODEL_ID: arn:aws:bedrock:ap-northeast-2::foundation-model/anthropic.claude-3-haiku-20240307-v1:0
  BEDROCK_REGION: ap-northeast-2

jobs:

  # ================================
  # 1) SCAN JOB
  # AWS???¤ì œë¡??‘ì†?´ì„œ Prowler ë³´ì•ˆ ?ê? ?˜í–‰
  # ================================
  scan:
    name: 1) Scan (Prowler CIS 1.4)
    if: github.event_name == 'push' || github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write   # OIDC role assume
    env:
      PROWLER_DASHBOARD_BUCKET: ${{ secrets.PROWLER_DASHBOARD_BUCKET }}
      PROWLER_DASHBOARD_PREFIX: ${{ secrets.PROWLER_DASHBOARD_PREFIX }}

    steps:
      # ?ˆí¬ ì½”ë“œ ì²´í¬?„ì›ƒ
      - name: Checkout repository
        uses: actions/checkout@v4

      # ê²°ê³¼ ?€???”ë ‰? ë¦¬ ?ì„±
      - name: Create working directories
        run: |
          mkdir -p output reports scripts mcp/output

      # Python ?˜ê²½ êµ¬ì„±
      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # GitHub OIDC ??AWS IAM Role Assume
      - name: Configure AWS credentials (OIDC assume-role)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ap-northeast-2

      # Prowler ë°?ë¦¬í¬???¼ì´ë¸ŒëŸ¬ë¦??¤ì¹˜
      - name: Install dependencies (Prowler + report tools)
        run: |
          pip install prowler pandas openpyxl boto3

      # CIS 1.4 ê¸°ì??¼ë¡œ AWS ?¤ìº” ?¤í–‰
      - name: Run Prowler scan (CIS 1.4 / ap-northeast-2)
        continue-on-error: true
        run: |
          prowler aws \
            --region ap-northeast-2 \
            --compliance cis_1.4_aws \
            --severity medium \
            --output-directory output \
            --output-formats json-ocsf html csv

      # S3 ?…ë¡œ??(?€?œë³´???°ë™?? ?¤ì •??ê²½ìš°?ë§Œ ?¤í–‰)
      - name: Upload CSV to S3 for dashboard (optional)
        if: ${{ secrets.PROWLER_DASHBOARD_BUCKET != '' }}
        env:
          BUCKET: ${{ secrets.PROWLER_DASHBOARD_BUCKET }}
          PREFIX: ${{ secrets.PROWLER_DASHBOARD_PREFIX }}
        run: |
          set -euo pipefail
          PREFIX="${PREFIX:-prowler/output/${{ github.run_id }}}"
          echo "Uploading CSVs to s3://$BUCKET/$PREFIX/"
          aws s3 cp output/ "s3://$BUCKET/$PREFIX/" --recursive --exclude "*" --include "*.csv"

      # ?ë³¸ ê²°ê³¼ ?„í‹°?©íŠ¸ ?…ë¡œ??(?¤ìŒ job?ì„œ ?¬ìš©)
      - name: "Upload artifacts: Prowler raw output"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: prowler-output
          path: output/


  # ================================
  # 2) PROCESS JOB
  # Scan ê²°ê³¼ë¥??•ê·œ???ìˆ˜??AIë³´ê°•/Runbook ?ì„±
  # ================================
  process:
    name: 2) Process (Normalize/Score/AI/Runbook/OCSF)
    runs-on: ubuntu-latest
    needs: scan
    if: needs.scan.result == 'success'
    permissions:
      contents: read
      id-token: write   # Bedrock ?¸ì¶œ ??OIDC assume-role ê°€?¥í•˜?„ë¡

    steps:
      # ?ˆí¬ ì½”ë“œ ì²´í¬?„ì›ƒ
      - name: Checkout repository
        uses: actions/checkout@v4

      # ?‘ì—… ?”ë ‰? ë¦¬ ?ì„±
      - name: Create working directories
        run: |
          mkdir -p output reports scripts mcp/output

      # scan job?ì„œ ?…ë¡œ?œí•œ ?ë³¸ ê²°ê³¼ ?¤ìš´ë¡œë“œ
      - name: "Download artifacts: Prowler raw output"
        uses: actions/download-artifact@v4
        with:
          name: prowler-output
          path: output

      # Python ?˜ê²½ êµ¬ì„±
      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # GitHub OIDC ??AWS IAM Role Assume (AI Assist?? fork PR?ì„œ??ê±´ë„ˆ?€)
      - name: Configure AWS credentials (OIDC assume-role)
        if: github.event_name == 'push' || github.event.pull_request.head.repo.fork != true
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ap-northeast-2

      # ?Œì´?„ë¼??ì²˜ë¦¬???¼ì´ë¸ŒëŸ¬ë¦??¤ì¹˜
      - name: Install dependencies (pipeline tools)
        run: |
          pip install pandas openpyxl boto3

      # Normalize ??Score ??AI Assist ??Runbook ??OCSF export
      - name: Process findings pipeline        env:
          BUCKET: ${{ env.PROWLER_DASHBOARD_BUCKET }}
          PREFIX: ${{ env.PROWLER_DASHBOARD_PREFIX }}
        run: |
          set -euo pipefail
          PREFIX="${PREFIX:-prowler/output/${{ github.run_id }}}"
          echo "Uploading CSVs to s3://$BUCKET/$PREFIX/"
          aws s3 cp output/ "s3://$BUCKET/$PREFIX/" --recursive --exclude "*" --include "*.csv"

      # ?ë³¸ ê²°ê³¼ ?„í‹°?©íŠ¸ ?…ë¡œ??(?¤ìŒ job?ì„œ ?¬ìš©)
      - name: "Upload artifacts: Prowler raw output"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: prowler-output
          path: output/


  # ================================
  # 2) PROCESS JOB
  # Scan ê²°ê³¼ë¥??•ê·œ???ìˆ˜??AIë³´ê°•/Runbook ?ì„±
  # ================================
  process:
    name: 2) Process (Normalize/Score/AI/Runbook/OCSF)
    runs-on: ubuntu-latest
    needs: scan
    if: needs.scan.result == 'success'
    permissions:
      contents: read
      id-token: write   # Bedrock ?¸ì¶œ ??OIDC assume-role ê°€?¥í•˜?„ë¡

    steps:
      # ?ˆí¬ ì½”ë“œ ì²´í¬?„ì›ƒ
      - name: Checkout repository
        uses: actions/checkout@v4

      # ?‘ì—… ?”ë ‰? ë¦¬ ?ì„±
      - name: Create working directories
        run: |
          mkdir -p output reports scripts mcp/output

      # scan job?ì„œ ?…ë¡œ?œí•œ ?ë³¸ ê²°ê³¼ ?¤ìš´ë¡œë“œ
      - name: "Download artifacts: Prowler raw output"
        uses: actions/download-artifact@v4
        with:
          name: prowler-output
          path: output

      # Python ?˜ê²½ êµ¬ì„±
      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # GitHub OIDC ??AWS IAM Role Assume (AI Assist?? fork PR?ì„œ??ê±´ë„ˆ?€)
      - name: Configure AWS credentials (OIDC assume-role)
        if: github.event_name == 'push' || github.event.pull_request.head.repo.fork != true
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ap-northeast-2

      # ?Œì´?„ë¼??ì²˜ë¦¬???¼ì´ë¸ŒëŸ¬ë¦??¤ì¹˜
      - name: Install dependencies (pipeline tools)
        run: |
          pip install pandas openpyxl boto3

      # Normalize ??Score ??AI Assist ??Runbook ??OCSF export
      - name: Process findings pipeline
        env:
          BEDROCK_MODEL_ID: ${{ env.BEDROCK_MODEL_ID }}
          BEDROCK_REGION: ap-northeast-2
          AWS_REGION: ap-northeast-2
          AWS_DEFAULT_REGION: ap-northeast-2
        run: |
          set -e

          # CSVê°€ ?ˆì„ ê²½ìš°ë§?ì²˜ë¦¬
          if ls output/*.csv >/dev/null 2>&1; then
            python mcp/pipeline/normalize.py \
              --input "output/*.csv" \
              --output mcp/output/findings-normalized.csv

            python mcp/pipeline/score.py \
              --input mcp/output/findings-normalized.csv \
              --output mcp/output/findings-scored.csv

            python mcp/pipeline/ai_assist.py \
              --input mcp/output/findings-scored.csv \
              --output mcp/output/findings-scored-ai.csv

            python mcp/pipeline/build_runbook.py \
              --input mcp/output/findings-scored-ai.csv \
              --template mcp/templates/runbook.md \
              --output mcp/output/runbook.md
          fi

          # OCSF export ì²˜ë¦¬
          if ls output/*.ocsf.json >/dev/null 2>&1; then
            python mcp/pipeline/export_ocsf.py \
              --input "output/*.ocsf.json" \
              --output mcp/output/ocsf-findings.json
          fi

      # ê°€ê³µëœ ê²°ê³¼ ?…ë¡œ??
      - name: "Upload artifacts: MCP processed output"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mcp-output
          path: mcp/output/


  # ================================
  # 3) REMEDIATE JOB
  # main push???Œë§Œ Terraform ì½”ë“œ ?ì„± + PR ?ë™ ?ì„±
  # ================================
  remediate:
    name: 3) Remediate (Generate IaC + Create PR)
    runs-on: ubuntu-latest
    needs: process
    # Gate ì¡°ê±´: main push???Œë§Œ ?¤í–‰
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    permissions:
      contents: write
      pull-requests: write
      id-token: write

    steps:
      # ë¸Œëžœì¹??ì„±/?¸ì‹œë¥??„í•´ full clone
      - name: Checkout repository (full history)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # MCP ê°€ê³?ê²°ê³¼ ?¤ìš´ë¡œë“œ
      - name: "Download artifacts: MCP processed output"
        uses: actions/download-artifact@v4
        with:
          name: mcp-output
          path: mcp/output

      # Python ?˜ê²½ êµ¬ì„±.
      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # GitHub OIDC ??AWS IAM Role Assume (Bedrock ?¸ì¶œ??
      - name: Configure AWS credentials (OIDC assume-role)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ap-northeast-2

      # IaC ë³´ì¡° ?¼ì´ë¸ŒëŸ¬ë¦??¤ì¹˜
      - name: Install IaC helper libraries
        run: |
          pip install pandas pyyaml boto3

      # Terraform CLI ?¤ì¹˜ (ê²€ì¦ìš©)
      - name: Setup Terraform CLI
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      # AI ê¸°ë°˜ Terraform remediation ì½”ë“œ ?ì„±
      - name: Generate Terraform remediation
        env:
          PREFER_IAC_SNIPPET: "false"
          BEDROCK_MODEL_ID: ${{ env.BEDROCK_MODEL_ID }}
          BEDROCK_REGION: ap-northeast-2
          AWS_REGION: ap-northeast-2
          AWS_DEFAULT_REGION: ap-northeast-2
        run: |
          mkdir -p remediation
          # ?´ë²ˆ ?¤í–‰?ì„œ ?ì„±???Œì¼ë§?? ì? (?´ì „ ê²°ê³¼ ?•ë¦¬)
          find remediation -type f ! -name '.gitkeep' -delete

          if [ -f mcp/output/findings-scored-ai.csv ]; then
            python mcp/pipeline/generate_remediation.py \
              --input mcp/output/findings-scored-ai.csv \
              --output-dir remediation/
          else
            echo "No scored findings found. Skipping remediation."
            exit 0
          fi

      # ?ì„±??.tf ?Œì¼???ˆì„ ê²½ìš° ì¹´í…Œê³ ë¦¬ë³?PR ?ì„±
      - name: Create remediation PRs (per category)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git remote set-url origin "https://x-access-token:${{ secrets.PROWLER_PAT }}@github.com/${{ github.repository }}.git"

          MANIFEST="remediation/manifest.json"
          if [ ! -f "$MANIFEST" ]; then
            echo "No manifest.json found; skipping PR creation."
            exit 0
          fi

          # ?ì„±???Œì¼???„ì‹œ ?”ë ‰?°ë¦¬??ë°±ì—… (checkout ??? ì‹¤ ë°©ì?)
          TMPGEN=$(mktemp -d)
          cp -r remediation/* "$TMPGEN/"
          echo "Backed up generated files to $TMPGEN"

          # manifest.json?ì„œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¶”ì¶œ
          CATEGORIES=$(python3 -c "
          import json, sys
          with open('$TMPGEN/manifest.json') as f:
              items = json.load(f)
          cats = sorted(set(item['category'] for item in items))
          for c in cats:
              print(c)
          ")

          if [ -z "$CATEGORIES" ]; then
            echo "No categories found in manifest."
            exit 0
          fi

          for CATEGORY in $CATEGORIES; do
            echo "=== Processing category: $CATEGORY ==="

            # ?´ë‹¹ ì¹´í…Œê³ ë¦¬ ?Œì¼ëª?ëª©ë¡ ì¶”ì¶œ (basenameë§?
            CAT_FILES=$(python3 -c "
          import json
          with open('$TMPGEN/manifest.json') as f:
              items = json.load(f)
          for item in items:
              if item['category'] == '$CATEGORY':
                  print(item['file'])
          ")

            if [ -z "$CAT_FILES" ]; then
              echo "No files for category $CATEGORY; skipping."
              continue
            fi

            BRANCH="remediation/$CATEGORY"
            git checkout -B "$BRANCH" main

            # main?ì„œ ?ì†???¤ë¥¸ ì¹´í…Œê³ ë¦¬ remediation ?Œì¼ ?œê±°
            git rm -f remediation/*.tf remediation/manifest.json 2>/dev/null || true
            mkdir -p remediation
            for fname in $CAT_FILES; do
              if [ -f "$TMPGEN/$fname" ]; then
                cp "$TMPGEN/$fname" "remediation/$fname"
                git add "remediation/$fname"
              fi
            done

            # ì¹´í…Œê³ ë¦¬ë³?manifest ?ì„± (ë¨¸ì? ì¶©ëŒ ë°©ì?)
            python3 -c "
          import json
          with open('$TMPGEN/manifest.json') as f:
              items = json.load(f)
          filtered = [i for i in items if i['category'] == '$CATEGORY']
          with open('remediation/manifest.json', 'w') as f:
              json.dump(filtered, f, indent=2)
          "
            git add remediation/manifest.json

            if [ -z "$(git diff --cached --name-only)" ]; then
              echo "No changes for $CATEGORY; skipping."
              continue
            fi

            FILE_COUNT=$(echo "$CAT_FILES" | wc -l | tr -d ' ')
            git commit -m "fix($CATEGORY): auto-generated Terraform remediation [$FILE_COUNT files]"
            git push origin "$BRANCH" --force

            # ê¸°ì¡´ PR???ˆìœ¼ë©??…ë°?´íŠ¸, ?†ìœ¼ë©??ì„±
            EXISTING_PR=$(gh pr list --head "$BRANCH" --base main --state open --json number --jq '.[0].number' 2>/dev/null || echo "")
            if [ -z "$EXISTING_PR" ]; then
              PR_BODY=$(python3 -c "
          import json
          with open('$TMPGEN/manifest.json') as f:
              items = json.load(f)
          lines = ['## Category: \`$CATEGORY\`', '', 'Auto-generated Terraform remediation from Prowler pipeline.', '', '**Files:** $FILE_COUNT remediation(s)', '', '### Included checks:']
          for item in items:
              if item['category'] == '$CATEGORY':
                  lines.append(f\"- [{item['priority']}] {item['check_title']} (\`{item['check_id']}\`)\")
          print('\n'.join(lines))
          ")
              gh pr create \
                --title "Security Remediation: $CATEGORY ($FILE_COUNT files)" \
                --body "$PR_BODY" \
                --base main \
                --head "$BRANCH"
              echo "Created PR for category: $CATEGORY"
            else
              echo "PR #${EXISTING_PR} already exists for ${BRANCH} ??updated via force-push."
            fi
          done

          rm -rf "$TMPGEN"

